{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "aRRpPAif9GOx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu, softmax\n",
        "from torch.optim import SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I like mozarella cheesy pizza\"\n",
        "words = text.lower().split()\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQsB2a0a-CEi",
        "outputId": "6de1f31c-0a8a-4435-e09b-c1ebf9877a26"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'like', 'mozarella', 'cheesy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs = []\n",
        "for word in words:\n",
        "  if word not in vocabs:\n",
        "    vocabs.append(word)\n",
        "\n",
        "vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwiWBCz2-OIc",
        "outputId": "1bc45fce-734a-4e3f-cbfc-232ce13116f6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'like', 'mozarella', 'cheesy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {word: i for i, word in enumerate(vocabs)}\n",
        "idx2word = {i: word for word, i in word2idx.items()}\n",
        "idx2word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWYit3bs-QtF",
        "outputId": "82eb42c7-4ced-4c7c-a511-17586cc7e2bc"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'i', 1: 'like', 2: 'mozarella', 3: 'cheesy', 4: 'pizza'}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 1\n",
        "data = []\n",
        "\n",
        "for i, word in enumerate(vocabs):\n",
        "  context_before = vocabs[max(0, i - window_size):i]\n",
        "  context_after = vocabs[i+1:min(len(vocabs), i+1+window_size)]\n",
        "\n",
        "  for context in context_before:\n",
        "    data.append((word, context))\n",
        "  for context in context_after:\n",
        "    data.append((word, context))\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsBykauD-TaT",
        "outputId": "0d0f216d-0ba7-4e15-c1fd-65b142e8d1cf"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 'like'),\n",
              " ('like', 'i'),\n",
              " ('like', 'mozarella'),\n",
              " ('mozarella', 'like'),\n",
              " ('mozarella', 'cheesy'),\n",
              " ('cheesy', 'mozarella'),\n",
              " ('cheesy', 'pizza'),\n",
              " ('pizza', 'cheesy')]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_transform(word, vocabs_size):\n",
        "  arr = np.zeros(vocabs_size)\n",
        "  arr[word2idx[word]] = 1\n",
        "  return arr"
      ],
      "metadata": {
        "id": "E_xG9iTB-V_i"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_inverse_transform(one_hot_encoded: np.ndarray):\n",
        "  return np.where(one_hot_encoded == 1)[0][0]"
      ],
      "metadata": {
        "id": "NhiYvyJi-WOg"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_input = np.array([one_hot_transform(i, len(vocabs)) for i in vocabs])\n",
        "onehot_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGgrUl_v-Yn7",
        "outputId": "b7b38301-58ad-4d5c-c4a7-6b4678712c30"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec(nn.Module):\n",
        "  def __init__(self, vocabs_size: int, lr: float = 0.01) -> None:\n",
        "    super().__init__()\n",
        "    self.embeddings_dimension = 3\n",
        "    self.vocabs_size = vocabs_size\n",
        "    self.w1 = nn.Parameter(torch.tensor(np.random.uniform(-1, 1, (vocabs_size, self.embeddings_dimension))), requires_grad=True)\n",
        "    self.w2 = nn.Parameter(torch.tensor(np.random.uniform(-1, 1, (self.embeddings_dimension, vocabs_size))), requires_grad=True)\n",
        "    self.learning_rate = lr\n",
        "\n",
        "  def forward(self, input_encoded) -> torch.Tensor:\n",
        "    h = torch.matmul(input_encoded, self.w1)\n",
        "    u = torch.matmul(h, self.w2)\n",
        "\n",
        "    # output = softmax(u, dim=-1)\n",
        "    return u\n",
        "\n",
        "  def get_optimizer(self) -> SGD:\n",
        "    return SGD(self.parameters(), lr=self.learning_rate)\n",
        "\n",
        "  def train(self, X: torch.Tensor, y: torch.Tensor, epochs: int = 100):\n",
        "    optimizer = self.get_optimizer()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      total_loss = 0\n",
        "\n",
        "      for x_train, label in zip(X, y):\n",
        "        y_pred = self.forward(x_train)\n",
        "        loss = criterion(y_pred, label)\n",
        "        loss.backward()\n",
        "        total_loss += float(loss)\n",
        "\n",
        "      if total_loss < 0.0001:\n",
        "        break\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      print(f'Epoch {epoch}: Loss {total_loss}')"
      ],
      "metadata": {
        "id": "3DNl3jG3-hBM"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(len(vocabs), lr=0.1)\n",
        "output = model(torch.tensor(onehot_input))\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRu5ghkKD5gM",
        "outputId": "27eddee7-e30f-4b05-c47a-d6b286f4de76"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3899,  0.3364,  0.5358,  0.3011,  0.4720],\n",
              "        [-0.3217, -1.2619,  0.6664,  0.5376, -0.1300],\n",
              "        [ 0.2469, -0.5536, -0.1277, -0.0517, -0.3102],\n",
              "        [ 0.9358, -0.5857, -0.0243, -0.1652, -0.2306],\n",
              "        [ 0.1305, -2.2047,  0.5609,  0.4937, -0.5854]], dtype=torch.float64,\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = torch.argmax(output, dim=1)\n",
        "print(f'Text: {text}')\n",
        "print(f'Prediction: {\" \".join([idx2word[int(i)] for i in y_pred])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J3Y934AHzf-",
        "outputId": "7a2cd1b6-b6b0-47d5-bb06-798638d5c17a"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I like mozarella cheesy pizza\n",
            "Prediction: mozarella mozarella i i mozarella\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for x, y in data:\n",
        "  X_train.append(one_hot_transform(x, len(vocabs)))\n",
        "  y_train.append(word2idx[y])\n",
        "print(f'X: {X_train}')\n",
        "print(f'y: {y_train}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge-4NGjLuGte",
        "outputId": "da73a733-91f5-4d88-d8c5-a8c570725a2b"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: [array([1., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0.]), array([0., 1., 0., 0., 0.]), array([0., 0., 1., 0., 0.]), array([0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0.]), array([0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 1.])]\n",
            "y: [1, 0, 2, 1, 3, 2, 4, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(torch.tensor(X_train), torch.tensor(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDI3ojWe3uki",
        "outputId": "77074ba6-d2b7-4fdd-f2fa-db3a95adc89d"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 13.128059698670869\n",
            "Epoch 1: Loss 12.129033919739198\n",
            "Epoch 2: Loss 11.400912831092677\n",
            "Epoch 3: Loss 10.791834119188726\n",
            "Epoch 4: Loss 10.236171726907187\n",
            "Epoch 5: Loss 9.704244292077515\n",
            "Epoch 6: Loss 9.184919165538881\n",
            "Epoch 7: Loss 8.677620321170126\n",
            "Epoch 8: Loss 8.187599870141522\n",
            "Epoch 9: Loss 7.7227829766603895\n",
            "Epoch 10: Loss 7.291612526195818\n",
            "Epoch 11: Loss 6.901364365890682\n",
            "Epoch 12: Loss 6.55662067079123\n",
            "Epoch 13: Loss 6.258250136496238\n",
            "Epoch 14: Loss 6.0035086538971365\n",
            "Epoch 15: Loss 5.787254948025664\n",
            "Epoch 16: Loss 5.603530569727123\n",
            "Epoch 17: Loss 5.446734417360708\n",
            "Epoch 18: Loss 5.312149737937187\n",
            "Epoch 19: Loss 5.196002875658103\n",
            "Epoch 20: Loss 5.09531464921381\n",
            "Epoch 21: Loss 5.007711360056235\n",
            "Epoch 22: Loss 4.931264208368186\n",
            "Epoch 23: Loss 4.8643724712951375\n",
            "Epoch 24: Loss 4.805685089147413\n",
            "Epoch 25: Loss 4.754049868540671\n",
            "Epoch 26: Loss 4.708480056430776\n",
            "Epoch 27: Loss 4.6681306369917435\n",
            "Epoch 28: Loss 4.632279582476838\n",
            "Epoch 29: Loss 4.600311609020942\n",
            "Epoch 30: Loss 4.571703481651774\n",
            "Epoch 31: Loss 4.54601067020223\n",
            "Epoch 32: Loss 4.522855420150691\n",
            "Epoch 33: Loss 4.501916308651221\n",
            "Epoch 34: Loss 4.482919273274347\n",
            "Epoch 35: Loss 4.4656300175064265\n",
            "Epoch 36: Loss 4.449847644570116\n",
            "Epoch 37: Loss 4.435399351211377\n",
            "Epoch 38: Loss 4.422136016233335\n",
            "Epoch 39: Loss 4.409928534242244\n",
            "Epoch 40: Loss 4.3986647655618905\n",
            "Epoch 41: Loss 4.3882469940028\n",
            "Epoch 42: Loss 4.378589802954667\n",
            "Epoch 43: Loss 4.3696182963568155\n",
            "Epoch 44: Loss 4.361266604479056\n",
            "Epoch 45: Loss 4.3534766254070725\n",
            "Epoch 46: Loss 4.346196962049971\n",
            "Epoch 47: Loss 4.33938202173641\n",
            "Epoch 48: Loss 4.332991251354626\n",
            "Epoch 49: Loss 4.3269884857812775\n",
            "Epoch 50: Loss 4.321341391245402\n",
            "Epoch 51: Loss 4.316020988457542\n",
            "Epoch 52: Loss 4.31100124293652\n",
            "Epoch 53: Loss 4.30625871209793\n",
            "Epoch 54: Loss 4.301772240417442\n",
            "Epoch 55: Loss 4.297522695420269\n",
            "Epoch 56: Loss 4.293492738433104\n",
            "Epoch 57: Loss 4.289666625013405\n",
            "Epoch 58: Loss 4.286030030780682\n",
            "Epoch 59: Loss 4.282569899046176\n",
            "Epoch 60: Loss 4.2792743071958546\n",
            "Epoch 61: Loss 4.276132349247037\n",
            "Epoch 62: Loss 4.273134032387864\n",
            "Epoch 63: Loss 4.2702701856344225\n",
            "Epoch 64: Loss 4.267532379013709\n",
            "Epoch 65: Loss 4.264912851910578\n",
            "Epoch 66: Loss 4.262404449410913\n",
            "Epoch 67: Loss 4.260000565637248\n",
            "Epoch 68: Loss 4.257695093212094\n",
            "Epoch 69: Loss 4.255482378102372\n",
            "Epoch 70: Loss 4.2533571791988445\n",
            "Epoch 71: Loss 4.251314632070294\n",
            "Epoch 72: Loss 4.249350216405578\n",
            "Epoch 73: Loss 4.24745972671957\n",
            "Epoch 74: Loss 4.245639245953065\n",
            "Epoch 75: Loss 4.243885121643227\n",
            "Epoch 76: Loss 4.242193944381237\n",
            "Epoch 77: Loss 4.2405625283085815\n",
            "Epoch 78: Loss 4.238987893433328\n",
            "Epoch 79: Loss 4.237467249573875\n",
            "Epoch 80: Loss 4.235997981760305\n",
            "Epoch 81: Loss 4.2345776369432\n",
            "Epoch 82: Loss 4.233203911876967\n",
            "Epoch 83: Loss 4.231874642059846\n",
            "Epoch 84: Loss 4.230587791625869\n",
            "Epoch 85: Loss 4.229341444095687\n",
            "Epoch 86: Loss 4.228133793903259\n",
            "Epoch 87: Loss 4.226963138624407\n",
            "Epoch 88: Loss 4.225827871841079\n",
            "Epoch 89: Loss 4.224726476582146\n",
            "Epoch 90: Loss 4.223657519287698\n",
            "Epoch 91: Loss 4.2226196442492645\n",
            "Epoch 92: Loss 4.221611568483196\n",
            "Epoch 93: Loss 4.22063207699877\n",
            "Epoch 94: Loss 4.219680018426382\n",
            "Epoch 95: Loss 4.218754300974551\n",
            "Epoch 96: Loss 4.217853888687589\n",
            "Epoch 97: Loss 4.216977797978374\n",
            "Epoch 98: Loss 4.216125094413203\n",
            "Epoch 99: Loss 4.215294889727776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(torch.tensor(onehot_input))\n",
        "y_pred = torch.argmax(output, dim=1)\n",
        "print(f'Text: {text}')\n",
        "print(f'Prediction: {\" \".join([idx2word[int(i)] for i in y_pred])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDFyov1J4scs",
        "outputId": "76493cf6-dbd5-406d-d790-95dc79a83972"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I like mozarella cheesy pizza\n",
            "Prediction: like i like mozarella cheesy\n"
          ]
        }
      ]
    }
  ]
}